# Problemas-de-aprendizaje
[Intermedio] Varianza, inclinación, Underfiting y Overfiting. Tecnicas de regulacion: L1, L2, Dropout, normalización.

# Varianza y Bias - Overfiting y Underfiting
La varianza y el sesgo son problemas recurrentes en machine learning. En la busqueda de un modelo que logre generalizar las relaciones entre las variables independientes y dependientes, convergemos a diferentes representaciones no adecuadas que podemos clasificar en funcion a la caracteristica intrinseca.

![image](https://media.licdn.com/dms/image/v2/C4E22AQH1UrwEMcBRfg/feedshare-shrink_2048_1536/feedshare-shrink_2048_1536/0/1653026422242?e=2147483647&v=beta&t=UIctBj9TdQeEWho68EZYJHr89lraDxUzhT4mucI33Rg)

![image](https://i.stack.imgur.com/eVFct.png)

# Regulacion
Para solucionar este tipo de problemas, podemos utilizar medidas de regulacion para converger al mejor modelo. Podemos limitar el tama;o de una arquitectura, o podemos implementar limites en el entrenamiento y arquitectura, este modulo aborda estos problemas.

